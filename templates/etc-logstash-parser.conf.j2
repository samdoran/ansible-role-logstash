input {
    redis {
        host => "{{ redis_host_1 }}"
        port => 5678
        data_type => "list"
        key => "logstash"
        codec => "json"
        threads => 1
    }

    redis {
        host => "{{ redis_host_2 }}"
        port => 5678
        data_type => "list"
        key => "logstash"
        codec => "json"
        threads => 1
    }
}


filter {

    # --- Tag things --- #

    # Tag session messages
    if [type] == "syslog" and [message] =~ /session (opened|closed) for user/ {
        mutate { add_tag => [ "session" ] }
    }

    # Tag login failures
    if [type] == "syslog" and [message] =~ /(?i:invalid user)|(authentication failure)|(Failed password)|(?i:login failure)/ {
        mutate { add_tag => [ "authfail" ] }
    }

    # Capture actual source host from file path
    if ([type] == "syslog") or ("nginx" in [tags]) or ("iis" in [tags]) {
        grok { match => [ "path" , "/var/log/remote/%{IPORHOST:actual_source_host}/" ] }

        if [host] != [actual_source_host] {
            mutate {
                replace => [ "host" , "%{actual_source_host}" ]
                remove_field => [ "actual_source_host" ]
            }
        }
        else {
            mutate { remove_field => [ "actual_source_host" ] }
        }
    }

    # Tag aerohive logs. This is based on the source IP address
    if [source_ip] =~ /192\.168\.40\.1[567][0-9]/ {
        mutate { add_tag => "aerohive" }
    }


    # --- Audit logs --- #
    # if [type] == "audit" {

    #     grok {
    #         type => "audit"
    #         patterns_dir => [ "/opt/logstash/patterns" ]
    #         pattern => [ "type=%{WORD:audit_type} msg=audit\(%{NUMBER:audit_epoch}:%{NUMBER:audit_counter}\): user pid=%{NUMBER:audit_pid} uid=%{NUMBER:audit_uid} auid=%{NUMBER:audit_audid} ses=%{NUMBER:audit_ses} subj=(?<audit_subj>[\w:\.-]+\b) msg=(?<audit_msg>[\'\S]+) acct=%{QUOTEDSTRING:audit_acct} exe=%{QUOTEDSTRING:audit_exe} hostname=(?<audit_hostname>\?|%{IPORHOST}) addr=(?<audit_addr>\?|%{IPORHOST}) terminal=%{TTY:audit_terminal} res=%{WORD:audit_res}" ]
    #         pattern => [ "type=%{WORD:audit_type} msg=audit\(%{NUMBER:audit_epoch}:%{NUMBER:audit_counter}\): arch=%{BASE16NUM:audit_arch} syscall=%{NUMBER:audit_syscall} per=%{NUMBER:audit_per} success=%{WORD:audit_success} exit=%{NUMBER:audit_exit} a0=%{NUMBER:audit_a0} a1=%{NUMBER:audit_a1} a2=%{NUMBER:audit_a2} a3=%{BASE16NUM:audit_a3} items=%{NUMBER:audit_items} ppid=%{NUMBER:audit_ppid} pid=%{NUMBER:audit_pid} auid=%{NUMBER:audit_auid} uid=%{NUMBER:audit_uid} gid=%{NUMBER:audit_gid} euid=%{NUMBER:euid} suid=%{NUMBER:suid} fsuid=%{NUMBER:fsuid} egid=%{NUMBER:egid} sgid=%{NUMBER:sgid} fsgid=%{NUMBER:
    #         ty=(?<audit_tty>\(none\)|%{TTY}) ses=%{NUMBER:audit_ses} comm=%{QUOTEDSTRING:audit_comm} exe=%{QUOTEDSTRING:audit_exe} subj=(?<audit_subj>[\w:\.-]+\b) key=%{QUOTEDSTRING:audit_key}" ]
    #         add_tag => "grokked"
    #     }

    #     date {
    #         match => [ "audit_epoch" , "UNIX_MS" ]
    #         add_tag => "dated"
    #     }
    # }

    # --- Nginx logs --- #
    if [type] == "nginx-access" {
        grok {
            patterns_dir => [ "/opt/logstash/patterns" ]
            match => [ "message" , "%{NGINX_ROYALL}" ]
            add_tag => [ "grokked" ]
        }

        useragent { source => "agent" }

        geoip {
            source => "clientip"
            database => "/opt/logstash/vendor/geoip/GeoLiteCity.dat"
        }
    }

    if [type] == "nginx-error" {
        grok {
            patterns_dir => [ "/opt/logstash/patterns" ]
            match => [ "message" , "%{NGINX_ERROR}" ]
            add_tag => [ "grokked" ]
        }

        geoip {
            source => "clientip"
            database => "/opt/logstash/vendor/geoip/GeoLiteCity.dat"
        }
    }

    # Extract first folder after domain
    if ("nginx" in [tags]) and ([request] =~ /\/.*\//) {
        grok {
            match => ["request", "/%{DATA:folder}/"]
        }
    }

    if "nginx" in [tags] {
        date {
            match => [ "timestamp" , "dd/MMM/yyyy:HH:mm:ss Z" , "yyyy/MM/dd HH:mm:ss" ]
            add_tag => "dated"
        }

        # Remove timestamp fields because it confuses ES
        mutate { remove_field => [ "timestamp" ] }
    }


    # --- Syslogs --- #
    if "sudo" in [tags] {
        grok {
            patterns_dir => [ "/opt/logstash/patterns" ]
            match => [ "message" , "%{SYSLOGTIMESTAMP} sudo:%{SPACE}%{USER:sudoer} : (\(command continued\) %{GREEDYDATA:command}|TTY=%{DATA:tty} ; PWD=%{PATH:pwd} ; USER=%{USER:user} ; COMMAND=%{GREEDYDATA:command})" ]
            add_tag => "grokked"
        }
    }


    if ("sshd" in [tags]) and ("session" in [tags]) {
        grok {
            patterns_dir => [ "/opt/logstash/patterns" ]
            match => [ "message" , "session (opened|closed) for user %{USER:user}" ]
            add_tag => "grokked"
        }
    }

    if ("sshd" in [tags]) and ("authfail" in [tags]) {
        grok {
            patterns_dir => [ "/opt/logstash/patterns" ]
            match => [ "message" , "(rhost=%{IPORHOST:host}%{SPACE}user=%{USER:user})|(?i:invalid user %{USER:user})|(Failed password for (invalid user %{USER:user}|%{USER:user}) from %{IPORHOST:authfail_host})|(Too many authentication failures for %{USER:user})" ]
            add_tag => "grokked"
        }
    }

    # TACACS
    if "tacacs" in [tags] {
        if "authfail" in [tags] {
            grok {
                patterns_dir => [ "/opt/logstash/patterns" ]
                match => [ "message" , "%{TACPLUS_LOGIN_FAIL}" ]
                add_tag => "grokked"
            }
        }

        # Drop noisy connect messages
        if "connect from" in [message] {
            drop {}
        }

        # Main command logging
        if [message] =~ /tty\d/ {
            grok {
                patterns_dir => [ "/opt/logstash/patterns" ]
                match => [ "message" , "%{TACPLUS}" ]
                add_tag => "grokked"
            }
        }
    }

    # --- Aerohive --- #

    # Change IP in host field to friendly hostname
    if "aerohive" in [tags] {
        grok { match => [ "host" , "192\.168\.40\.%{INT:last_octet}" ] }

        if [last_octet] == "155" {
            mutate {
                replace => [ "host" , "AP330-%{last_octet}" ]
            }
        } else {
            mutate {
                replace => [ "host" , "AP121-%{last_octet}" ]
            }
        }

        mutate { remove_field => [ "last_octet" ] }
    }

    # Extract IP, station, hostname, BSSID, etc.
    if ("aerohive" in [tags]) and ("ah_rt_sta_update_hostname:" in [message]) {
        grok {
            patterns_dir => [ "/opt/logstash/patterns" ]
            match => [ "message" , "ah_rt_sta_update_hostname: %{AEROHIVEMAC:station}\(hostname=%{DATA:hostname}\)" ]
            add_tag => "grokked"
        }
    }

    if ("aerohive" in [tags]) and ("ah_rt_sta_update_ip:" in [message]) {
        grok {
            patterns_dir => [ "/opt/logstash/patterns" ]
            match => [ "message" , "ah_rt_sta_update_ip: %{AEROHIVEMAC:station}\(ip=%{IP:clientip}\)" ]
            add_tag => "grokked"
        }
    }

    if ("aerohive" in [tags]) and ("ah_rt_sta_update_ip_hostname:" in [message]) {
        grok {
            patterns_dir => [ "/opt/logstash/patterns" ]
            match => [ "message" , "ah_rt_sta_update_ip_hostname: %{AEROHIVEMAC:station} ip=%{IP:clientip}, hostname=%{GREEDYDATA:hostname}" ]
            add_tag => "grokked"
        }
    }

    if ("aerohive" in [tags]) and ("ah_auth: ah_rt_sta_add:" in [message]) {
        grok {
            patterns_dir => [ "/opt/logstash/patterns" ]
            match => [ "message" , "ah_auth: ah_rt_sta_add: %{AEROHIVEMAC:station}\(ip=%{IP:clientip}\), username %{GREEDYDATA:user} on %{GREEDYDATA:interface}" ]
            add_tag => "grokked"
        }
    }

    if ("aerohive" in [tags]) and ("detect station" in [message]) {
        grok {
            patterns_dir => [ "/opt/logstash/patterns" ]
            match => [ "message" , " ah_auth: detect station\(%{AEROHIVEMAC:station}\) os\(%{DATA:os}\) via DHCP fingerprint" ]
            add_tag => "grokked"
        }
    }

    if ("aerohive" in [tags]) and ([message] =~ /is (de-)?authenticated (to|from)/) {
        grok {
            patterns_dir => [ "/opt/logstash/patterns" ]
            match => [ "message" , "ah_auth: Station %{AEROHIVEMAC:station} is (de-)?authenticated (to|from) %{AEROHIVEMAC:bssid} thru SSID %{GREEDYDATA:ssid}" ]
            add_tag => "grokked"
        }
    }

    if ("aerohive" in [tags]) and ([message] =~ /ah_auth: Station ([A-Fa-f0-9]{4}:){2}[A-Fa-f0-9]{4} ip/) {
        grok {
            patterns_dir => [ "/opt/logstash/patterns" ]
            match => [ "message" , "ah_auth: Station %{AEROHIVEMAC:station} ip %{IP:clientip} username %{DATA:user} hostname %{DATA:hostname} OS %{GREEDYDATA:os}" ]
            add_tag => "grokked"
        }
    }

    if ("aerohive" in [tags]) and ([message] =~ /ah_auth: sta [A-Fa-f0-9]{4}/) {
        grok {
            patterns_dir => [ "/opt/logstash/patterns" ]
            match => [ "message" , "ah_auth: sta %{AEROHIVEMAC:station} is disassociated from %{AEROHIVEMAC:bssid}\(%{DATA:interface}\) in driver" ]
            add_tag => "grokked"
        }
    }

    if ("aerohive" in [tags]) and ([message] =~ /ah_auth: Notify driver to disassoc [A-Fa-f0-9]{4}/) {
        grok {
            patterns_dir => [ "/opt/logstash/patterns" ]
            match => [ "message" , "ah_auth: Notify driver to disassoc %{AEROHIVEMAC:station} from %{GREEDYDATA:interface}" ]
            add_tag => "grokked"
        }
    }

    if ("aerohive" in [tags]) and ([message] =~ /receive driver notification/) {
        grok {
            patterns_dir => [ "/opt/logstash/patterns" ]
            match => [ "message" , "receive driver notification\[%{DATA}, %{WORD:event}\] for Sta\[%{AEROHIVEMAC:station}\] at Hapd\[%{AEROHIVEMAC:bssid}, %{GREEDYDATA:interface}\]" ]
            add_tag => "grokked"
        }
    }

     if ("aerohive" in [tags]) and ("pmksa_cache_auth_add" in [message]) {
        grok {
            patterns_dir => [ "/opt/logstash/patterns" ]
            match => [ "message" , "ah_auth: pmksa_cache_auth_add: own_addr %{AEROHIVEMAC:bssid}, sta %{AEROHIVEMAC:station}, %{INT}, username %{GREEDYDATA:user}" ]
            add_tag => "grokked"
        }
    }

    if ("aerohive" in [tags]) and ("L2 DoS" in [message]) {
        grok {
            patterns_dir => [ "/opt/logstash/patterns" ]
            match => [ "message" , "L2 DoS: interface %{NOTSPACE:interface}\(%{DATA:ssid}\) station %{AEROHIVEMAC:station}:" ]
            add_tag => [ "grokked" , "l2dos" ]
        }
    }

    # --- IIS --- #

    if "iis" in [tags] {
        # Drop comment lines from IIS
        if [message] =~ /^#/ {
            drop {}
        }

        if "iis5" in [tags] {
            grok {
                match => ["message", "%{DATESTAMP:eventtime} %{IPORHOST:clientip} (-|%{USER:user}|(%{WORD:domain}[\\/]?%{USER:user})|(%{USER:user}@%{NOTSPACE:domain})) %{IPORHOST:upstream} %{NUMBER:port} %{NOTSPACE:verb} %{DATA:request} (?:%{DATA:param}|-)(?: %{DATA:agent}|-)"]
                add_tag => [ "grokked" ]
            }
        }

        if "iis6" in [tags] {
            grok {
                match => ["message", "%{DATESTAMP:eventtime} %{WORD:site} %{IPORHOST:upstream} %{NOTSPACE:verb} %{DATA:request} (?:%{DATA:param}|-) %{NUMBER:port} (-|%{USER:user}|(%{WORD:domain}[\\/]?%{USER:user})|(%{USER:user}@%{NOTSPACE:domain})) %{IPORHOST:clientip}(?: %{DATA:agent}|-) %{NUMBER:response} %{NUMBER:status} %{NUMBER:win32Status}"]
                add_tag => [ "grokked" ]
            }
        }

        # Change '+' to ' ' since IIS uses '+' as a delimeter in the
        # user agent string
        mutate {
            gsub => [ agent , "\+" , " " ]
        }

        useragent { source => "agent" }

        geoip {
            source => "clientip"
            database => "/opt/logstash/vendor/geoip/GeoLiteCity.dat"
        }

        # Extract first folder after domain
        if [request] =~ /\/.*\// {
            grok {
                match => ["request", "/%{DATA:folder}/"]
            }
        }

        if "_grokparsefailure" not in [tags] {
            date {
                match => [ "eventtime" , "yy-MM-dd HH:mm:ss" ]
                add_tag => "dated"
                remove_field => [ "eventtime" ]
            }
        }
    }

    # --- Exchange --- #

    if "exchange" in [tags] {
        # Drop comment and blank lines
        if [message] =~ /(^#)|(^$)/ {
            drop {}
        }

        grok {
            patterns_dir => [ "/opt/logstash/patterns" ]
            match => ["message", "%{EXCHANGELOGS}"]
            add_tag => [ "grokked" ]
        }

        # Take tabs out of timestamp
        mutate {
            gsub => [ "eventtime" , "\t", " " ]
        }

        date {
            match => [ "eventtime" , "yyyy-M-d H:m:s z" ]
            add_tag => "dated"
            remove_field => [ "eventtime" ]
        }
    }
}

output {

    # stdout { debug => true }

    elasticsearch {
        bind_host => "{{ ansible_default_ipv4.address }}"
        cluster => "{{ es_cluster_name }}"
        node_name => "{{ ansible_hostname }}"
        port => "9500-9600"
        flush_size => 500
    }
}
